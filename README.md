# Jarvis UI

A modern web interface for Jarvis AI Assistant with native streaming support and easy model swapping.

![Jarvis UI](https://via.placeholder.com/800x400?text=Jarvis+UI+Screenshot)

## Features

- ğŸš€ **Real-time Streaming** - Native WebSocket streaming for instant token-by-token responses
- ğŸ”„ **Easy Model Swapping** - Switch between OpenAI, Anthropic, or local models via config
- ğŸ’¾ **Session Persistence** - Chat history saved across page reloads
- ğŸ› ï¸ **Tool Execution** - AI can control your infrastructure via n8n tools
- ğŸ¨ **Modern UI** - Beautiful dark theme with smooth animations
- ğŸ“± **Responsive Design** - Works on desktop and mobile devices

## Architecture

The system uses a **backend-hosted LLM architecture** where the FastAPI backend directly communicates with LLM providers, with n8n serving as a tool executor:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚ (Port 20006)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ WebSocket (streaming)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend (Port 20005)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LLM Orchestrator                            â”‚ â”‚
â”‚  â”‚  - Direct LLM API calls (streaming)          â”‚ â”‚
â”‚  â”‚  - Tool/function calling                     â”‚ â”‚
â”‚  â”‚  - Session & memory management               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Tool Registry                               â”‚ â”‚
â”‚  â”‚  - Built-in: calculator, memory, time        â”‚ â”‚
â”‚  â”‚  - n8n: system, docker, services, jellyfin   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP (only for tool execution)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  n8n Tool       â”‚     â”‚  PostgreSQL+PGVector â”‚
â”‚  Executor       â”‚     â”‚  - sessions          â”‚
â”‚  (Port 20003)   â”‚     â”‚  - messages          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  - long_term_memory  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Architecture?

| Feature | Benefit |
|---------|---------|
| **Native Streaming** | Token-by-token responses via WebSocket |
| **Low Latency** | Direct LLM calls, no n8n overhead |
| **Model Flexibility** | Switch providers via environment variable |
| **Simple Debugging** | Python logging instead of n8n execution traces |

## Prerequisites

- **Python 3.10+** - [Download](https://python.org)
- **Node.js 18+** - [Download](https://nodejs.org)
- **PostgreSQL with PGVector** - Running on your target machine
- **n8n** - With tool workflows configured
- **OpenAI API Key** (or other LLM provider)

## Quick Start

### 1. Clone and Setup

```powershell
# Clone the repository
git clone <repository-url>
cd jarvis-ui

# Run the setup script
.\scripts\setup.ps1
```

### 2. Configure Environment

Edit `backend/.env` with your settings:

```env
# Server
HOST=0.0.0.0
PORT=20005

# PostgreSQL connection
DATABASE_URL=postgresql+asyncpg://n8n:n8npass@192.168.1.100:20004/jarvis
MEMORY_DATABASE_URL=postgresql+asyncpg://n8n:n8npass@192.168.1.100:20004/memory

# LLM Provider (openai, anthropic, or local)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
OPENAI_API_KEY=sk-your-key-here

# n8n Tool Executor webhook
N8N_TOOL_EXECUTOR_URL=http://192.168.1.100:20003/webhook/tool-executor
N8N_TIMEOUT_SECONDS=120
```

### 3. Run Database Migrations

```powershell
.\scripts\migrate.ps1
```

### 4. Start the Application

```powershell
# Start both frontend and backend
.\scripts\start.ps1

# Or start them separately:
.\scripts\start-backend.ps1  # In one terminal
.\scripts\start-frontend.ps1 # In another terminal
```

### 5. Access the UI

- **Development**: http://localhost:20006
- **Production**: http://localhost:20005
- **API Docs**: http://localhost:20005/docs

## Project Structure

```
jarvis-ui/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ db.py            # Database connection
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ session.py       # Session model
â”‚   â”‚   â””â”€â”€ message.py       # Message model
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ api.py           # REST API endpoints
â”‚   â”‚   â””â”€â”€ websocket.py     # WebSocket handler (streaming)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_provider.py  # LLM abstraction layer
â”‚   â”‚   â”œâ”€â”€ tool_registry.py # Tool definitions
â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # AI orchestration
â”‚   â”‚   â”œâ”€â”€ n8n_client.py    # n8n tool executor client
â”‚   â”‚   â””â”€â”€ session_manager.py
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ jarvis.py        # Jarvis system prompt
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.jsx
â”‚   â”‚   â”‚   â””â”€â”€ MessageInput.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ websocket.js # WebSocket with streaming
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ session.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ n8n/
â”‚   â”œâ”€â”€ workflows/           # n8n tool workflows
â”‚   â””â”€â”€ docs/
â”‚       â””â”€â”€ workflows-summary.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.ps1
â”‚   â”œâ”€â”€ migrate.ps1
â”‚   â”œâ”€â”€ start.ps1
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

## Configuration Options

### Backend Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `HOST` | Server bind address | `0.0.0.0` |
| `PORT` | Server port | `20005` |
| `DATABASE_URL` | PostgreSQL connection (jarvis db) | Required |
| `MEMORY_DATABASE_URL` | PostgreSQL connection (memory db) | Required |
| `LLM_PROVIDER` | LLM provider: openai, anthropic, gemini, local | `openai` |
| `LLM_MODEL` | Model name | `gpt-4o` |
| `OPENAI_API_KEY` | OpenAI API key | Required if using OpenAI |
| `ANTHROPIC_API_KEY` | Anthropic API key | Required if using Anthropic |
| `GEMINI_API_KEY` | Google Gemini API key | Required if using Gemini |
| `N8N_TOOL_EXECUTOR_URL` | n8n tool executor webhook URL | Required |
| `N8N_TIMEOUT_SECONDS` | Timeout for n8n requests | `120` |
| `CORS_ORIGINS` | Allowed CORS origins | `*` |
| `SESSION_TTL_DAYS` | Session expiration days | `30` |

### Switching LLM Providers

```bash
# OpenAI (default)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o
OPENAI_API_KEY=sk-...

# Anthropic Claude
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-opus-20240229
ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini
LLM_PROVIDER=gemini
LLM_MODEL=gemini-1.5-pro
GEMINI_API_KEY=your-gemini-api-key

# Local (Ollama)
LLM_PROVIDER=local
LLM_MODEL=llama3
LOCAL_LLM_URL=http://localhost:11434
```

## n8n Tool Executor Setup

The backend calls n8n for infrastructure tools. Set up a single "Tool Executor" workflow:

### Tool Executor Webhook

Create a webhook workflow that routes to your existing tool workflows:

```
POST /webhook/tool-executor
Body: {
  "tool": "docker_control",
  "params": { "action": "ps" }
}

Response: {
  "status": "success",
  "result": { ... }
}
```

### Available Tools

| Tool | Description |
|------|-------------|
| `system_status` | CPU, memory, disk, network info |
| `docker_control` | Manage Docker containers |
| `service_control` | Manage systemd services |
| `jellyfin_api` | Jellyfin media server API |
| `ssh_command` | Execute SSH commands with sudo |
| `gemini_cli` | Query Gemini AI |
| `n8n_workflow` | Manage n8n workflows |

## API Endpoints

### REST API

- `GET /api/health` - Health check
- `GET /api/history/{session_id}` - Get chat history
- `GET /api/session/{session_id}` - Check if session exists

### WebSocket

Connect to: `ws://localhost:20005/ws/{session_id}`

**Client â†’ Server Messages:**
```json
{"type": "message", "content": "Hello!"}
{"type": "get_history"}
{"type": "stop"}
```

**Server â†’ Client Messages (Streaming):**
```json
{"type": "stream_start"}
{"type": "stream_token", "content": "Hello"}
{"type": "stream_token", "content": ", Sir"}
{"type": "stream_end", "full_content": "Hello, Sir!"}
{"type": "tool_call", "tool": "docker_control", "params": {...}}
{"type": "tool_result", "result": {...}}
{"type": "error", "content": "..."}
```

## Development

### Running in Development Mode

```powershell
# Terminal 1: Backend with hot reload
.\scripts\start-backend.ps1

# Terminal 2: Frontend with hot reload
.\scripts\start-frontend.ps1
```

### Building for Production

```powershell
# Build the frontend
.\scripts\build.ps1

# The backend will serve the built frontend
.\scripts\start-backend.ps1
```

## Troubleshooting

### Connection Issues

1. **Cannot connect to PostgreSQL**
   - Verify the database server is running
   - Check firewall allows connections on port 20004
   - Verify credentials in `DATABASE_URL`

2. **LLM API errors**
   - Verify your API key is correct
   - Check the model name is valid
   - Ensure you have API credits

3. **Tool execution fails**
   - Verify n8n is running on port 20003
   - Check the Tool Executor webhook is active
   - Check n8n execution logs

4. **Streaming not working**
   - Ensure WebSocket connection is established
   - Check browser console for errors
   - Verify no proxy is buffering responses

### Common Errors

- **"Virtual environment not found"**: Run `.\scripts\setup.ps1` first
- **"Migration failed"**: Check `DATABASE_URL` and network connectivity
- **"LLM provider not found"**: Check `LLM_PROVIDER` env var
- **"Tool execution timeout"**: Increase `N8N_TIMEOUT_SECONDS`

## Future Roadmap

- [ ] Speech-to-text input
- [ ] Text-to-speech output
- [ ] Image upload/display
- [ ] File sharing
- [ ] Android app (React Native)
- [ ] User authentication
- [ ] Multi-user support

## License

MIT License
